### Week 01

1주차 

#### Machine Learning
- Machine Learing 적용 예시 
  - 문서 분류, 주가 예측, 번호판 인식, SNS 추천 서비스 등
- Machine Learing 종류
  - Supervised Learing(지도학습)
    - 정답 데이터가 주어진 다음, 답을 예측하는 문제
  - Un-supervised Learing(비지도학습)
    - 답을 모르는 상황에서 데이터를 요약하고 군집을 찾는 문제

#### 기본 지식
- 간단한 확률 문제
  - 압정을 5번 던져 결과를 예측하는 문제
    - 5번 던져 3번 못이 위로 향했다고 해서 항상 3/5 라고 말할 수 있는가? No.
  - **Binomial Distribution (이항 분포)**
    - 결과가 Yes or No 둘 중 하나로 정해져있는 상황에서 n번의 독립적인 실험을 했을 때 성공한 횟수에 대한 discrete probability distribution(이산 확률 분포)
    - 각 실험(베르누이 실험)에서 성공할 확률 : θ 
    - 압정을 던졌을 때 각각의 실험은 I.I.D를 만족
      - IID : Independent Identically Distributed
    - 압정의 못이 위를 바라보는 사건 : H
    - 아래를 바라보는 사건 : T
    - H가 나올 확률 : P(H) = θ 
    - T가 나올 확률 : P(T) = 1 - θ
      - 한번의 실험에 대해 나올 수 있는 모든 경우의 확률의 합은 1을 충족하므로. 
    - 그러므로 압정을 n번 던져 결과가 나올 확률은 아래와 같다.
      - $ P(D| \theta) =\theta^{ a_H} (1-\theta)^{a_T}$
    - 그렇다면 "압정을 던져 위를 향할 확률을 구할 때, 그 결과는 θ라는 이산확률 분포를 따른다"는 어떻게 주장할 수 있을까?
- **Maximum Likelihood Estimation (최대 우도법)**
  - 어떤 θ를 선택했을 때 주어진 데이터를 가장 잘 설명할 수 있을까? 
    - 그래서 나온 개념이 MLE 라는 확률의 추론 방법
    - 역으로 θ를 찾아내는 것 : $ \hat{\theta} $
    - $$ \hat{\theta} =\argmax\limits_{\theta}P(D|\theta) $$

  - 위 수식을 풀어서 썼을 때, 자승을 처리하기 쉽지 않기에 log func을 이용한다. P(D|θ)가 최대가 되는 지점과 lnP(D|θ)가 최대가 되는 지점이 같기에 이를 사용
    - 이는 극대값(최댓값) 문제로 볼 수 있으며, 도함수를 이용하여 극점을 찾으면 됨
  - 이러한 실험을 "여러번" 진행한다면 추정에 대한 에러를 점차 줄이고, 더 정확한 예측 가능 
  - 또한 허용할 수 있는 Error Bound가 커지면 커질 수록 확률은 작아지기 때문에 **추정된 θ와 실제 θ의 차이가 작다**는 의미
  - 즉, Probably Approximately Correct(PAC) Lenaring의 결과물이 θ이 되는 것
- **Maximum a Posteriori Estimation (최대 사후 확률)**
  - 사전 지식을 가미해서 $ \theta $을 추정하는 것 
  - 즉, 주어진 관측 결과와 사전 확률을 결합해 최적의 모수를 찾아내는 방법이며, 데이터와 제일 잘 맞는 추정치를 찾고 주어진 데이터를 기반으로 최대 확률을 갖는 파라미터를 찾음
  - 즉, 우리가 알고 있는 사전 정보인 prior의 정보를 likelihood에 곱하여 반영함으로써 더 정확한 판단을 내림
  - 하지만 잘못된 사전 지식을 입력할 경우 결과물이 좋지 않을 수 있음
  
  > **딥러닝이랑 결국 데이터의 분포에 모델 파라미터를 근사시키는 과정**이기에 MLE, MAP, 베이지안(MLE와 MAP는 베이지안의 근간) 모두 이 아이디어에서 근거한 개념이기 이므로 딥러닝을 하려면 꼭 알아야 하는 개념 중 하나
  > 출처 : https://ebbnflow.tistory.com/330 

  >MAE의 단점
  > 1. Uncertainty를 계산할 수 있는 방법이 없음, 결과를 얼마나 신뢰할 수 있는지를 측정할 기준이 하지만, MAP에서는 이를 측정할 수 있는 명확한 기준 없음 
  > 2. Overfitting, 우리가 Uncertainty를 측정할 수 있는 방법이 없기 때문에, 예측 정확도를 높이는 데에만 집중하다보면 분포가 overfitting 될 수 있음 
  > 출처 : https://process-mining.tistory.com/126

- #### **Probability and Distribution (확률 분포)**
  - 조건부 확률 : 어떤 사건이 일어나는 경우에 다른 사건이 일어날 확률
  - 확률 분포 : 확률 변수가 특정한 값을 가질 확률을 나타내는 함수 
  - 정규 분포 : 또는 가우스 분포는 연속 확률 분포의 하나
    - 수집된 자료의 분포를 근사하는 데에 자주 사용되며, 중심극한정리에 의하여 독립적인 확률변수들의 평균은 정규분포에 가까워지는 성질 존재 
    - 정규분포는 2개의 매개 변수 평균 $ {\displaystyle \mu } $ 과 표준편차 ${\displaystyle \sigma }$ 에 대해 모양이 결정되고, 이때의 분포를 ${\displaystyle \mathrm  {N}  (\mu ,\sigma ^{2})}$ ${\mathrm  {N}}(\mu ,\sigma ^{2})$로 표기함
      - 평균이 0이고 표준편차가 1인 정규분포 $ {\displaystyle \mathrm {N} (0,1)}$ 
  - 베타 분포
    - 정규 분포는 정의역의 범위가 무한대이지만 베타분포는 정의역의 범위가 [0, 1]로 정해져 있음 
  - 이항 분포
  - 다항 분포 

